<!DOCTYPE HTML>
<html>
	<head>
		<title>AIRET: The First International Workshop on Agentic Intelligence: Risks, Ethics, and Trust</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="css/skel.css" />
		<link rel="stylesheet" href="css/style.css" />
		<link rel="stylesheet" href="css/style-xlarge.css" />
		<link rel="stylesheet" href="css/font-awesome.min.css" />
		<script src="js/jquery.min.js"></script>
		<script src="js/jquery.scrollzer.min.js"></script>
		<script src="js/jquery.scrolly.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-layers.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-xlarge.css" />
			<link rel="stylesheet" href="css/font-awesome.min.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
	</head>
<body>
    <div id='wrapper'>
        <section id='header' class='skel-layers-fixed'>
            <nav id='nav'>
                <ul>
                    <li><a href='#overview' class='active'>Overview</a></li>
                    <li><a href='#themes'>Themes & Topics</a></li>
                    <li><a href='#submission'>Submission</a></li>
                    <li><a href='#dates'>Important Dates</a></li>
                    <li><a href='#organizers'>Organizers</a></li>
                </ul>
            </nav>
        </section>
        <div id='main'>
            <section id='one'>
                <div class='container'>
                    <header class='major'>
                        <h1>AIRET 2025</h1>
                    </header>
                    <h3 class='workshop-title'>The First International Workshop on<br>
                        <span class='initials'>A</span>gentic <span class='initials'>I</span>ntelligence: <span class='initials'>R</span>isks, <span class='initials'>E</span>thics, and <span class='initials'>T</span>rust</h3>
                    <div class='workshop-details'>
                        <h4>Co-located with <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/'>IEEE CogMI 2025</a></h4>
                        <p class='date-location'>November 2025 in Pittsburgh, PA</p>
                    </div>
                </div>
            </section>
            <section id='overview'>
                <div class='container'>
                    <h2>Overview</h2>
                    <div class='description-content'>
                        <p>Artificial intelligence (AI) has entered a new phase marked by the rise of <strong>agentic systems</strong>—autonomous entities capable of planning, adapting, and acting over time toward goals. Unlike conventional AI models that operate within fixed boundaries or reactive paradigms, agentic AI embodies dynamic, proactive behavior that can reshape digital and physical environments. This shift demands a <strong>fundamental rethinking of risk and threat models, ethical frameworks, socio-technical solutions, and governance strategies</strong>.</p>

                        <p>The <em>Workshop on Agentic Intelligence: Risks, Ethics, and Trust (AIRET)</em> is motivated by the urgent need to address the complexities introduced by agentic AI. These systems challenge existing assumptions about controllability, oversight, and accountability. Risks such as instrumental convergence, emergent behavior, or self-preservation, as well as intended and unintended harms to individuals and society, are <strong>no longer speculative but are becoming practical concerns</strong>. Similarly, ethical questions about manipulation, responsibility, and human autonomy gain new urgency when intelligent agents act on our behalf—or against our interests—without direct supervision.</p>

                        <p>This workshop invites a cross-disciplinary audience, including AI researchers, ethicists, legal scholars, cybersecurity and privacy experts, and policy makers. Our goal is to foster a shared vocabulary and critical perspective on how agentic AI redefines the landscape of AI safety and ethics. We aim to <strong>bridge socio-technical insights with philosophical and regulatory foresight</strong>, charting a course toward systems that are not only powerful but also principled, accountable, and aligned with human and societal values.</p>
                    </div>
                </div>
            </section>
            <section id='themes'>
                <div class='container'>
                    <h2>Themes & Topics of Interest</h2>
                    <div class='description-content'>
                        <p>We encourage submissions addressing the risks, ethical implications, technical architectures, and governance of agentic AI systems. Topics of interest include, but are not limited to:</p>
                        
                        <h3><i class="fa fa-exclamation-triangle theme-icon"></i>Risks and Harms</h3>
                        <ul>
                            <li>Instrumental convergence and power-seeking behavior</li>
                            <li>Goal misalignment and reward hacking in long-horizon agents</li>
                            <li>Irreversibility and loss of oversight in autonomous deployment</li>
                            <li>Emergent behaviors in multi-agent ecosystems</li>
                            <li>Unintended generalization of capabilities</li>
                            <li>Threat models, risk frameworks, and understanding of intended and unintended harms</li>
                        </ul>
                        
                        <h3><span class="theme-icon">&#9878;</span>Ethics</h3>
                        <ul>
                            <li>Moral responsibility and accountability in autonomous decisions</li>
                            <li>Value alignment across dynamic and uncertain contexts</li>
                            <li>Human manipulation, persuasion, or deception by agents</li>
                            <li>The impact of over-delegation on human autonomy and critical thinking</li>
                            <li>Long-term ethical risks beyond bias and fairness</li>
                        </ul>
                        
                        <h3><i class="fa fa-university theme-icon"></i>Policy and Governance</h3>
                        <ul>
                            <li>Legal liability and accountability frameworks for agentic AI</li>
                            <li>Thresholds for safe deployment and escalation control</li>
                            <li>Dual-use concerns and malicious applications (e.g., cyberwarfare, finance)</li>
                            <li>Auditability and explainability of autonomous behavior over time</li>
                            <li>International governance and standards for agentic AI oversight</li>
                        </ul>
                        
                        <h3><i class="fa fa-shield theme-icon"></i>Cybersecurity, Privacy, and Trust</h3>
                        <ul>
                            <li>Resilience and containment of autonomous and adaptive systems</li>
                            <li>Strategic manipulation of information and infrastructure</li>
                            <li>Cybersecurity and privacy risks from multi-agent interactions (e.g., collusion, conflict escalation)</li>
                            <li>Threat modeling and defenses</li>
                            <li>New paradigms for agent containment and monitoring</li>
                            <li>Frameworks and methods for trust and trustworthiness in Agentic AI</li>
                            <li>Accountability and transparency frameworks</li>
                        </ul>
                        
                        <h3><i class="fa fa-cogs theme-icon"></i>Technology and Architectures</h3>
                        <ul>
                            <li>Planning, memory, and goal management in open environments</li>
                            <li>Tool use, API chaining, and real-world actuation</li>
                            <li>Episodic and semantic memory for long-term autonomy</li>
                            <li>Self-modification and dynamic learning strategies</li>
                            <li>Multi-agent coordination, competition, and negotiation</li>
                            <li>Benchmarking and simulation of persistent agent behavior</li>
                            <li>Scalable human-in-the-loop oversight mechanisms</li>
                            <li>Privacy-enhancing technologies, security solutions for end-to-end protection</li>
                        </ul>
                    </div>
                </div>
            </section>
            <section id='submission'>
                <div class='container'>
                    <h2>Submission Instructions</h2>
                    <div class='description-content'>
                        <p>We welcome three types of contributions:</p>
                        <ul>
                            <li><strong>Regular Technical Papers</strong> (up to 10 pages)</li>
                            <li><strong>Extended Abstracts</strong> (2–4 pages)</li>
                            <li><strong>Position Papers</strong> (1–10 pages)</li>
                        </ul>
                        
                        <p>All submissions must follow the same submission guidelines and instructions for the main conference (IEEE <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/call-for-full-papers/' target='_blank'>CogMI</a>, with the IEEE two-column conference format). Templates are available from the IEEE website.</p>
                        
                        <p><strong>Submissions must be made through EasyChair.</strong><br>
                        Select the track: "Workshop on Agentic Intelligence: Risks, Ethics, and Trust (AIRET)"</p>
                        
                        <p>Each submission will be reviewed by the workshop's Program Committee. Accepted papers will be included in the CogMI 2025 Workshop Proceedings, published by IEEE, and will be included in IEEE Xplore. At least one author must register and attend to present the work.</p>
                    </div>
                </div>
            </section>
            <section id='dates'>
                <div class='container'>
                    <h2>Important Dates</h2>
                    <div class='description-content'>
                        <ul class='important-dates'>
                            <li><strong>Submission deadline:</strong> Sep 7, 2025</li>
                            <li><strong>Acceptance notification:</strong> Sep 25, 2025</li>
                            <li><strong>Final version due:</strong> Oct 2, 2025</li>
                        </ul>
                    </div>
                </div>
            </section>
            <section id='organizers'>
                <div class='container'>
                    <h2>Workshop Organizers</h2>
                    
                    <h3>General Co-Chairs</h3>
                    <div class='organizer-grid'>
                        <a href='http://www.yurulin.com/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/yuru_lin.jpg' alt='Yu-Ru Lin'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Yu-Ru Lin</h4>
                                <p class='affiliation'>University of Pittsburgh</p>
                            </div>
                        </a>
                        
                        <a href='https://www.sis.pitt.edu/jjoshi/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/james_joshi.png' alt='James Joshi'>
                            </div>
                            <div class='organizer-info'>
                                <h4>James Joshi</h4>
                                <p class='affiliation'>University of Pittsburgh</p>
                            </div>
                        </a>
                        
                        <a href='https://scholars.cmu.edu/4994-tae-wan-kim' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/tae_wan_kim.png' alt='Tae Wan Kim'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Tae Wan Kim</h4>
                                <p class='affiliation'>Carnegie Mellon University</p>
                            </div>
                        </a>
                    </div>
                    
                    <h3>Program Committee Co-Chairs</h3>
                    <div class='organizer-grid'>
                        <a href='https://www.cs.emory.edu/~kshu5/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/kai_shu.png' alt='Kai Shu'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Kai Shu</h4>
                                <p class='affiliation'>Emory University</p>
                            </div>
                        </a>
                        
                        <a href='https://emiehling.github.io/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/erik_miehling.png' alt='Erik Miehling'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Erik Miehling</h4>
                                <p class='affiliation'>IBM Research</p>
                            </div>
                        </a>
                    </div>
                    
                    <h3>Publicity Chair</h3>
                    <div class='organizer-grid'>
                        <a href='https://andaqu.github.io/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/andrew_aquilina.jpg' alt='Andrew Aquilina'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Andrew Aquilina</h4>
                                <p class='affiliation'>University of Pittsburgh</p>
                            </div>
                        </a>


                        <div class='organizer-card' style='opacity:0; pointer-events:none; height:0; overflow:hidden;'></div>

                    </div>
                   
                </div>
            </section>
        </div>
    </div>
</body>
</html> 