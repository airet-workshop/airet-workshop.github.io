<!DOCTYPE HTML>
<html>
	<head>
		<title>AIRET: The First International Workshop on Agentic Intelligence: Risks, Ethics, and Trust</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="css/skel.css" />
		<link rel="stylesheet" href="css/style.css" />
		<link rel="stylesheet" href="css/style-xlarge.css" />
		<link rel="stylesheet" href="css/font-awesome.min.css" />
		<script src="js/jquery.min.js"></script>
		<script src="js/jquery.scrollzer.min.js"></script>
		<script src="js/jquery.scrolly.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-layers.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-xlarge.css" />
			<link rel="stylesheet" href="css/font-awesome.min.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
	</head>
<body>
    <div id='wrapper'>
        <section id='header' class='skel-layers-fixed'>
            <nav id='nav'>
                <ul>
                    <li><a href='#overview' class='active'>Overview</a></li>
                    <li><a href='#keynote'>Keynote</a></li>
                    <li><a href='#themes'>Themes & Topics</a></li>
                    <li><a href='#submission'>Submission</a></li>
                    <li><a href='#dates'>Important Dates</a></li>
                    <li><a href='#registration'>Registration</a></li>
                    <li><a href='#organizers'>Organizers</a></li>
                    <li><a href='#sponsors'>Sponsors</a></li>
                </ul>
            </nav>
        </section>
        <div id='main'>
            <section id='one'>
                <div class='container'>
                    <header class='major'>
                        <h1>AIRET 2025</h1>
                    </header>
                    <h3 class='workshop-title'>The First International Workshop on<br>
                        <span class='initials'>A</span>gentic <span class='initials'>I</span>ntelligence: <span class='initials'>R</span>isks, <span class='initials'>E</span>thics, and <span class='initials'>T</span>rust</h3>
                    <div class='workshop-details'>
                        <h4>Co-located with <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/'>IEEE CogMI 2025</a></h4>
                        <p class='date-location'>November 11 2025 in Pittsburgh, PA</p>
                    </div>
                </div>
            </section>
            <section id='overview'>
                <div class='container'>
                    <h2>Overview</h2>
                    <div class='description-content'>
                        <p>Artificial intelligence (AI) has entered a new phase marked by the rise of <strong>agentic systems</strong>—autonomous entities capable of planning, adapting, and acting over time toward goals. Unlike conventional AI models that operate within fixed boundaries or reactive paradigms, agentic AI embodies dynamic, proactive behavior that can reshape digital and physical environments. This shift demands a <strong>fundamental rethinking of risk and threat models, ethical frameworks, socio-technical solutions, and governance strategies</strong>.</p>

                        <p>The <em>Workshop on Agentic Intelligence: Risks, Ethics, and Trust (AIRET)</em> is motivated by the urgent need to address the complexities introduced by agentic AI. These systems challenge existing assumptions about controllability, oversight, and accountability. Risks such as instrumental convergence, emergent behavior, or self-preservation, as well as intended and unintended harms to individuals and society, are <strong>no longer speculative but are becoming practical concerns</strong>. Similarly, ethical questions about manipulation, responsibility, and human autonomy gain new urgency when intelligent agents act on our behalf—or against our interests—without direct supervision.</p>

                        <p>This workshop invites a cross-disciplinary audience, including AI researchers, ethicists, legal scholars, cybersecurity and privacy experts, and policy makers. Our goal is to foster a shared vocabulary and critical perspective on how agentic AI redefines the landscape of AI safety and ethics. We aim to <strong>bridge socio-technical insights with philosophical and regulatory foresight</strong>, charting a course toward systems that are not only powerful but also principled, accountable, and aligned with human and societal values.</p>
                    </div>
                </div>
            </section>
            <section id='keynote'>
                <div class='container'>
                    <h2>Keynote Speaker</h2>
                    <div class='keynote-speaker'>
                        <div class='keynote-image'>
                            <img src='images/vincent_conitzer.jpg' alt='Vincent Conitzer'>
                        </div>
                        <div class='keynote-info'>
                            <h3><a href='https://www.cs.cmu.edu/~conitzer/' target='_blank'>Vincent Conitzer</a></h3>
                            <p class='keynote-title'>Director, Foundations of Cooperative AI Lab<br>
                            Professor of Computer Science<br>
                            Carnegie Mellon University</p>
                            <p class='keynote-bio'>
                                Vincent Conitzer is Professor of Computer Science (with affiliate/courtesy appointments in Machine Learning, Philosophy, and the Tepper School of Business) at Carnegie Mellon University, where he directs the Foundations of Cooperative AI Lab (FOCAL). He is also Head of Technical AI Engagement at the Institute for Ethics in AI, and Professor of Computer Science and Philosophy, at the University of Oxford.
                            </p>
                            <p class='keynote-bio'>
                                Previous to joining CMU, Conitzer was the Kimberly J. Jenkins Distinguished University Professor of New Technologies and Professor of Computer Science, Professor of Economics, and Professor of Philosophy at Duke University. He received Ph.D. (2006) and M.S. (2003) degrees in Computer Science from Carnegie Mellon University, and an A.B. (2001) degree in Applied Mathematics from Harvard University.
                            </p>
                            <p class='keynote-links'>
                                <a href='https://www.cs.cmu.edu/~conitzer/' target='_blank'><i class="fa fa-home"></i> Homepage</a>
                            </p>
                        </div>
                    </div>
                </div>
            </section>
            <section id='themes'>
                <div class='container'>
                    <h2>Themes & Topics of Interest</h2>
                    <div class='description-content'>
                        <p>We encourage submissions addressing the risks, ethical implications, technical architectures, and governance of agentic AI systems. Topics of interest include, but are not limited to:</p>
                        
                        <h3><i class="fa fa-exclamation-triangle theme-icon"></i>Risks and Harms</h3>
                        <ul>
                            <li>Instrumental convergence and power-seeking behavior</li>
                            <li>Goal misalignment and reward hacking in long-horizon agents</li>
                            <li>Irreversibility and loss of oversight in autonomous deployment</li>
                            <li>Emergent behaviors in multi-agent ecosystems</li>
                            <li>Unintended generalization of capabilities</li>
                            <li>Threat models, risk frameworks, and understanding of intended and unintended harms</li>
                        </ul>
                        
                        <h3><span class="theme-icon">&#9878;</span>Ethics</h3>
                        <ul>
                            <li>Moral responsibility and accountability in autonomous decisions</li>
                            <li>Value alignment across dynamic and uncertain contexts</li>
                            <li>Human manipulation, persuasion, or deception by agents</li>
                            <li>The impact of over-delegation on human autonomy and critical thinking</li>
                            <li>Long-term ethical risks beyond bias and fairness</li>
                        </ul>
                        
                        <h3><i class="fa fa-university theme-icon"></i>Policy and Governance</h3>
                        <ul>
                            <li>Legal liability and accountability frameworks for agentic AI</li>
                            <li>Thresholds for safe deployment and escalation control</li>
                            <li>Dual-use concerns and malicious applications (e.g., cyberwarfare, finance)</li>
                            <li>Auditability and explainability of autonomous behavior over time</li>
                            <li>International governance and standards for agentic AI oversight</li>
                        </ul>
                        
                        <h3><i class="fa fa-shield theme-icon"></i>Cybersecurity, Privacy, and Trust</h3>
                        <ul>
                            <li>Resilience and containment of autonomous and adaptive systems</li>
                            <li>Strategic manipulation of information and infrastructure</li>
                            <li>Cybersecurity and privacy risks from multi-agent interactions (e.g., collusion, conflict escalation)</li>
                            <li>Threat modeling and defenses</li>
                            <li>New paradigms for agent containment and monitoring</li>
                            <li>Frameworks and methods for trust and trustworthiness in Agentic AI</li>
                            <li>Accountability and transparency frameworks</li>
                        </ul>
                        
                        <h3><i class="fa fa-cogs theme-icon"></i>Technology and Architectures</h3>
                        <ul>
                            <li>Planning, memory, and goal management in open environments</li>
                            <li>Tool use, API chaining, and real-world actuation</li>
                            <li>Episodic and semantic memory for long-term autonomy</li>
                            <li>Self-modification and dynamic learning strategies</li>
                            <li>Multi-agent coordination, competition, and negotiation</li>
                            <li>Benchmarking and simulation of persistent agent behavior</li>
                            <li>Scalable human-in-the-loop oversight mechanisms</li>
                            <li>Privacy-enhancing technologies, security solutions for end-to-end protection</li>
                            <li>Agentic AI for Social Simulations</li>
                        </ul>
                    </div>
                </div>
            </section>
            <section id='submission'>
                <div class='container'>
                    <h2>Submission Instructions</h2>
                    <div class='description-content'>
                        <p>We welcome three types of contributions:</p>
                        <ul>
                            <li><strong>Regular Technical Papers</strong> (up to 10 pages)</li>
                            <li><strong>Extended Abstracts</strong> (2–4 pages)</li>
                            <li><strong>Position Papers</strong> (up to 10 pages)</li>
                        </ul>
                        
                        <p>All submissions must follow the same submission guidelines and instructions for the main conference (IEEE <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/call-for-full-papers/' target='_blank'>CogMI</a>, with the IEEE two-column conference format). Templates are available from the IEEE website.</p>
                        
                        <p><strong>Submissions must be made through EasyChair.</strong><br>
                        Select the track: "Workshop on Agentic Intelligence: Risks, Ethics, and Trust (AIRET)"</p>
                        
                        <p>Each submission will be reviewed by the workshop's Program Committee. Accepted papers will be included in the CogMI 2025 Workshop Proceedings, published by IEEE, and will be included in IEEE Xplore. At least one author must register and attend to present the work.</p>
                    </div>
                </div>
            </section>
            <section id='dates'>
                <div class='container'>
                    <h2>Important Dates</h2>
                    <div class='description-content'>
                        <ul class='important-dates'>
                            <li><strong>Submission deadline:</strong> Sep 25, 2025</li>
                            <li><strong>Acceptance notification:</strong> Oct 10, 2025</li>
                            <li><strong>Author registration deadline:</strong> Oct 20, 2025</li>
                            <li><strong>Camera-ready submission deadline:</strong> Oct 25, 2025</li>
                        </ul>
                        <p style='margin-top: 15px;'><em>Please complete registration and camera-ready submission as soon as possible.</em></p>
                    </div>
                </div>
            </section>
            <section id='registration'>
                <div class='container'>
                    <h2>Registration & Camera-Ready Submission</h2>
                    <div class='description-content'>
                        <h3><i class="fa fa-ticket theme-icon"></i>Author Registration</h3>
                        <p><strong>At least one author must complete Workshop Author registration for each paper accepted.</strong> If you would like to attend both Workshop and Conference, you can complete Conference Author registration instead. Please see the <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/registration/' target='_blank'>registration page</a> for more information.</p>
                        <p><strong>Deadline:</strong> October 20, 2025</p>
                        
                        <h3><i class="fa fa-file-text theme-icon"></i>Camera-Ready Submission</h3>
                        <p>For camera-ready submission, please follow the instructions at the <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/camera-ready/' target='_blank'>camera-ready submission page</a>. Note that all workshop papers are included as part of the IEEE CogMI proceedings.</p>
                        <p><strong>Deadline:</strong> October 25, 2025</p>
                        
                        <h3><i class="fa fa-hotel theme-icon"></i>Hotel Registration</h3>
                        <p>For hotel reservations, please visit the <a href='https://book.passkey.com/event/51107555/owner/2945954/home' target='_blank'>hotel booking page</a>.</p>
                    </div>
                </div>
            </section>
            <section id='organizers'>
                <div class='container'>
                    <h2>Workshop Organizers</h2>
                    
                    <h3>General Co-Chairs</h3>
                    <div class='organizer-grid'>
                        <a href='http://www.yurulin.com/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/yuru_lin.jpg' alt='Yu-Ru Lin'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Yu-Ru Lin</h4>
                                <p class='affiliation'>University of Pittsburgh</p>
                            </div>
                        </a>
                        
                        <a href='https://www.sis.pitt.edu/jjoshi/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/james_joshi.png' alt='James Joshi'>
                            </div>
                            <div class='organizer-info'>
                                <h4>James Joshi</h4>
                                <p class='affiliation'>University of Pittsburgh</p>
                            </div>
                        </a>
                        
                        <a href='https://scholars.cmu.edu/4994-tae-wan-kim' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/tae_wan_kim.png' alt='Tae Wan Kim'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Tae Wan Kim</h4>
                                <p class='affiliation'>Carnegie Mellon University</p>
                            </div>
                        </a>
                    </div>
                    
                    <h3>Program Committee Co-Chairs</h3>
                    <div class='organizer-grid'>
                        <a href='https://www.cs.emory.edu/~kshu5/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/kai_shu.png' alt='Kai Shu'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Kai Shu</h4>
                                <p class='affiliation'>Emory University</p>
                            </div>
                        </a>
                        
                        <a href='https://emiehling.github.io/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/erik_miehling.png' alt='Erik Miehling'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Erik Miehling</h4>
                                <p class='affiliation'>IBM Research</p>
                            </div>
                        </a>
                    </div>
                    
                    <h3>Publicity Chair</h3>
                    <div class='organizer-grid'>
                        <a href='https://andaqu.github.io/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/andrew_aquilina.jpg' alt='Andrew Aquilina'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Andrew Aquilina</h4>
                                <p class='affiliation'>University of Pittsburgh</p>
                            </div>
                        </a>


                        <div class='organizer-card' style='opacity:0; pointer-events:none; height:0; overflow:hidden;'></div>

                    </div>
                   
                </div>
            </section>
            <section id='sponsors'>
                <div class='container'>
                    <h2>Sponsors</h2>
                    <div class='sponsors-content'>
                        <p>We gratefully acknowledge the support of our sponsors:</p>
                        <div class='sponsors-images'>
                            <img src='images/rds.png' alt='University of Pittsburgh - Office of the Provost Responsible Data Science'>
                            <img src='images/cyber.png' alt='University of Pittsburgh - Institute for Cyber Law, Policy, and Security'>
                        </div>
                    </div>
                </div>
            </section>
        </div>
    </div>
</body>
</html> 
