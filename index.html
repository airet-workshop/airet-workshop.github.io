<!DOCTYPE HTML>
<html>
	<head>
		<title>AIRET: The First International Workshop on Agentic Intelligence: Risks, Ethics, and Trust</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="css/skel.css" />
		<link rel="stylesheet" href="css/style.css" />
		<link rel="stylesheet" href="css/style-xlarge.css" />
		<link rel="stylesheet" href="css/font-awesome.min.css" />
		<script src="js/jquery.min.js"></script>
		<script src="js/jquery.scrollzer.min.js"></script>
		<script src="js/jquery.scrolly.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-layers.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-xlarge.css" />
			<link rel="stylesheet" href="css/font-awesome.min.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
	</head>
<body>
    <div id='wrapper'>
        <section id='header' class='skel-layers-fixed'>
            <nav id='nav'>
                <ul>
                    <li><a href='#overview' class='active'>Overview</a></li>
                    <li><a href='#program'>Program</a></li>
                    <li><a href='#keynote'>Keynote</a></li>
                    <li><a href='#spotlight'>Invited Spotlight Talk</a></li>
                    <li><a href='#panel'>Panel</a></li>
                    <li><a href='#themes'>Themes & Topics</a></li>
                    <li><a href='#submission'>Submission</a></li>
                    <li><a href='#dates'>Important Dates</a></li>
                    <li><a href='#registration'>Registration</a></li>
                    <li><a href='#organizers'>Organizers</a></li>
                    <li><a href='#sponsors'>Sponsors</a></li>
                </ul>
            </nav>
        </section>
        <div id='main'>
            <section id='one'>
                <div class='container'>
                    <header class='major'>
                        <h1>AIRET 2025</h1>
                    </header>
                    <h3 class='workshop-title'>The First International Workshop on<br>
                        <span class='initials'>A</span>gentic <span class='initials'>I</span>ntelligence: <span class='initials'>R</span>isks, <span class='initials'>E</span>thics, and <span class='initials'>T</span>rust</h3>
                    <div class='workshop-details'>
                        <h4>Co-located with <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/'>IEEE CogMI 2025</a></h4>
                        <p class='date-location'>November 11 2025 in Pittsburgh, PA</p>
                    </div>
                </div>
            </section>
            <section id='overview'>
                <div class='container'>
                    <h2>Overview</h2>
                    <div class='description-content'>
                        <p>Artificial intelligence (AI) has entered a new phase marked by the rise of <strong>agentic systems</strong>—autonomous entities capable of planning, adapting, and acting over time toward goals. Unlike conventional AI models that operate within fixed boundaries or reactive paradigms, agentic AI embodies dynamic, proactive behavior that can reshape digital and physical environments. This shift demands a <strong>fundamental rethinking of risk and threat models, ethical frameworks, socio-technical solutions, and governance strategies</strong>.</p>

                        <p>The <em>Workshop on Agentic Intelligence: Risks, Ethics, and Trust (AIRET)</em> is motivated by the urgent need to address the complexities introduced by agentic AI. These systems challenge existing assumptions about controllability, oversight, and accountability. Risks such as instrumental convergence, emergent behavior, or self-preservation, as well as intended and unintended harms to individuals and society, are <strong>no longer speculative but are becoming practical concerns</strong>. Similarly, ethical questions about manipulation, responsibility, and human autonomy gain new urgency when intelligent agents act on our behalf—or against our interests—without direct supervision.</p>

                        <p>This workshop invites a cross-disciplinary audience, including AI researchers, ethicists, legal scholars, cybersecurity and privacy experts, and policy makers. Our goal is to foster a shared vocabulary and critical perspective on how agentic AI redefines the landscape of AI safety and ethics. We aim to <strong>bridge socio-technical insights with philosophical and regulatory foresight</strong>, charting a course toward systems that are not only powerful but also principled, accountable, and aligned with human and societal values.</p>
                    </div>
                </div>
            </section>
            <section id='program'>
                <div class='container'>
                    <h2>Workshop Program</h2>
                    <div class='description-content'>
                        <p>The workshop will take place on <strong>November 11, 2025</strong>. Below is the detailed program schedule:</p>
                        
                        <div class='program-table-wrapper'>
                            <table class='program-table'>
                                <thead>
                                    <tr>
                                        <th>Time</th>
                                        <th>Workshop</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td data-label='Time'><strong>7:00 am – 8:30 am</strong></td>
                                        <td data-label='Event'>Breakfast</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>8:30 am – 8:45 am</strong></td>
                                        <td data-label='Event'>Opening</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>8:45 am – 9:45 am</strong></td>
                                        <td data-label='Event'><em>Paper Presentation</em><br><strong>Session 1:</strong> Trust, Governance, and Ethics in Multi-Agent AI Systems</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>9:45 am – 10:00 am</strong></td>
                                        <td data-label='Event'>Coffee Break</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>10:00 am – 11:00 am</strong></td>
                                        <td data-label='Event'><em>Keynote: Dr. Vincent Conitzer, CMU</em><br><strong>Game Theory for AI Agents</strong></td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>11:00 am – 12:00 pm</strong></td>
                                        <td data-label='Event'><em>AIRET Panel</em><br><strong>Panelists:</strong><br>- Vincent Conitzer, Director, Foundations of Cooperative AI Lab, Professor, CMU<br>- Ross McGowan, VP, Global Head of AI, TDK SensEI<br>- Thanh Tran, Applied Science Manager, Amazon Inc<br>- Derek Leben, Associate Teaching Professor of Ethics, Tepper School of Business, CMU<br><strong>Moderator:</strong> Yu-Ru Lin, Professor, U. Pitt | Research & Academic Director, Pitt Cyber Institute</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>12:00 pm – 1:30 pm</strong></td>
                                        <td data-label='Event'>Lunch time window</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>1:30 pm – 2:30 pm</strong></td>
                                        <td data-label='Event'><em>Paper Presentation</em><br><strong>Session 2:</strong> Security, Risk, and Control of Intelligent Agents</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>2:30 pm – 3:30 pm</strong></td>
                                        <td data-label='Event'><em>Paper Presentation</em><br><strong>Session 3:</strong> Human-Centered Design and Optimization</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>3:30 pm – 3:45 pm</strong></td>
                                        <td data-label='Event'>Coffee</td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>3:45 pm – 4:30 pm</strong></td>
                                        <td data-label='Event'><em>Spotlight Talk: Dr. Thanh Tran, Amazon Inc.</em><br><strong>MobiTwin: Toward Building End-to-End Framework for User's Mobile Twins</strong></td>
                                    </tr>
                                    <tr>
                                        <td data-label='Time'><strong>4:30 pm – 5:00 pm</strong></td>
                                        <td data-label='Event'>Closing Conversation + Adjournment</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                </div>
            </section>
            <section id='keynote'>
                <div class='container'>
                    <h2>Keynote Speaker</h2>
                    <div class='keynote-speaker'>
                        <div class='keynote-image'>
                            <img src='images/vincent_conitzer.jpg' alt='Vincent Conitzer'>
                        </div>
                        <div class='keynote-info'>
                            <h3><a href='https://www.cs.cmu.edu/~conitzer/' target='_blank'>Vincent Conitzer</a></h3>
                            <p><a href='https://www.cs.cmu.edu/~conitzer/' target='_blank'><i class="fa fa-home"></i> Homepage</a></p>
                            <p class='keynote-title'>Director, Foundations of Cooperative AI Lab<br>
                            Professor of Computer Science<br>
                            Carnegie Mellon University</p>
                            <p class='keynote-bio'>
                                Vincent Conitzer is Professor of Computer Science (with affiliate/courtesy appointments in Machine Learning, Philosophy, and the Tepper School of Business) at Carnegie Mellon University, where he directs the Foundations of Cooperative AI Lab (FOCAL). He is also Head of Technical AI Engagement at the Institute for Ethics in AI, and Professor of Computer Science and Philosophy, at the University of Oxford.
                            </p>
                            <p class='keynote-bio'>
                                Previous to joining CMU, Conitzer was the Kimberly J. Jenkins Distinguished University Professor of New Technologies and Professor of Computer Science, Professor of Economics, and Professor of Philosophy at Duke University. He received Ph.D. (2006) and M.S. (2003) degrees in Computer Science from Carnegie Mellon University, and an A.B. (2001) degree in Applied Mathematics from Harvard University.
                            </p>
                            <div class='keynote-abstract'>
                                <h4>Talk: Game Theory for AI Agents</h4>
                                <p>As agentic AI systems are deployed, they will increasingly interact with each other. Game theory is the study of entities that interact while pursuing their own objectives. But AI agents are not like humans or groups of humans. Their memories can be wiped, multiple copies of them can be spun up, they can be run in simulation, and their source code can be analyzed. In principle, the framework of game theory is flexible enough to accommodate all these aspects; but historically, the game theory community has not focused on them, and some of the relevant work has taken place in philosophy. I will discuss our work on these topics, with a focus on enabling AI agents to be cooperative in ways that humans cannot. (No previous background in game theory required.)</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <section id='spotlight'>
                <div class='container'>
                    <h2>Invited Spotlight Talk</h2>
                    <div class='keynote-speaker'>
                        <div class='keynote-image'>
                            <img src='images/ThanhTran-headshot (1).jpeg' alt='Thanh Tran'>
                        </div>
                        <div class='keynote-info'>
                            <h3>Thanh Tran</h3>
                            <p class='keynote-title'>Applied Science Manager<br>
                            Amazon</p>
                            <p class='keynote-bio'>
                                Thanh Tran is an Applied Science Manager at Amazon, where he leads the Agentic User Simulation initiative within Amazon Benchmarking. Over the past four years, Thanh has driven several large-scale AI initiatives, including Responsible AI guardrail development and evaluation for Amazon's Nova foundational model (2024), Retrieval-Augmented Generation and LLM training for Alexa, and the expansion of large language model context length from 2K to 32K tokens (2023). Earlier, he led efforts to enhance Alexa's natural language understanding through user historical context embeddings and end-to-end contextual signal interpretation in Alexa Speech. His work bridges scalable AI systems, user simulation, and responsible innovation, advancing the next trustworthy generation of intelligent system.
                            </p>
                            <div class='keynote-abstract'>
                                <h4>Talk: MobiTwin: Toward Building End-to-End Framework for User's Mobile Twins</h4>
                                <p>Understanding and anticipating user behavior at scale requires the ability to construct realistic digital twins that emulate real human decision-making. We introduce MobiTwin, an end-to-end framework for high-fidelity mobile user simulation designed to overcome key limitations of existing approaches: limited decision-making diversity, inability in multi-option processing, and limited interaction fidelity within mobile environments. To address, MobiTwin integrates four core components including adaptive persona generation, self-evolving contextual memory, multi-faceted behavioral simulation, and high-fidelity mobile device control to model user cognition and behavior. Unlike traditional methods that model user behaviors in isolation, MobiTwin enables simulated agents to perform joint decision-making across multiple options, closely mirroring how real users navigate cognitive trade-offs under screen. Empirical evaluations on both public benchmarks and proprietary datasets demonstrate that MobiTwin achieved significant gain in decision prediction accuracy, more robustness to positional bias, and computational efficiency compared to leading baselines. Beyond quantitative performance, we validate the fidelity of simulated agents through reasoning and emotion perception analyses, showing substantial behavioral alignment with human data.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <section id='panel'>
                <div class='container'>
                    <h2>Panel Discussion</h2>
                    <div class='description-content'>
                        <h3 style='margin-bottom: 20px;'>The Human Role in Agentic AI Futures</h3>
                        <p style='margin-bottom: 30px;'>Join our distinguished panelists for a thought-provoking discussion on the evolving role of humans in the age of agentic AI systems.</p>
                    </div>
                    
                    <h3 style='margin-bottom: 20px;'>Panelists</h3>
                    <div class='organizer-grid'>
                        <div class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/vincent_conitzer.jpg' alt='Vincent Conitzer'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Dr. Vincent Conitzer</h4>
                                <p class='affiliation'>Director, Foundations of Cooperative AI Lab<br>Professor of Computer Science<br>Carnegie Mellon University
                            </div>
                        </div>
                        
                        <div class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/ross_IMG_1709.jpeg' alt='Ross McGowan'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Mr. Ross McGowan</h4>
                                <p class='affiliation'>Vice President, Global Head of AI<br>TDK SensEI</p>
                            </div>
                        </div>
                        
                        <div class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/ThanhTran-headshot (1).jpeg' alt='Thanh Tran'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Dr. Thanh Tran</h4>
                                <p class='affiliation'>Applied Science Manager<br>Amazon Inc</p>
                            </div>
                        </div>
                        
                        <div class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/derek.jpg' alt='Derek Leben'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Dr. Derek Leben</h4>
                                <p class='affiliation'>Associate Teaching Professor of Ethics<br>Tepper School of Business<br>Carnegie MelAlon University</p>
                            </div>
                        </div>
                    </div>
                    
                    <h3 style='margin-bottom: 20px; margin-top: 40px;'>Moderator</h3>
                    <div class='organizer-grid'>
                        <div class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/yuru_lin.jpg' alt='Yu-Ru Lin'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Dr. Yu-Ru Lin</h4>
                                <p class='affiliation'>Professor<br>University of Pittsburgh<br>Pitt Cyber Institute</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <section id='themes'>
                <div class='container'>
                    <h2>Themes & Topics of Interest</h2>
                    <div class='description-content'>
                        <p>We encourage submissions addressing the risks, ethical implications, technical architectures, and governance of agentic AI systems. Topics of interest include, but are not limited to:</p>
                        
                        <h3><i class="fa fa-exclamation-triangle theme-icon"></i>Risks and Harms</h3>
                        <ul>
                            <li>Instrumental convergence and power-seeking behavior</li>
                            <li>Goal misalignment and reward hacking in long-horizon agents</li>
                            <li>Irreversibility and loss of oversight in autonomous deployment</li>
                            <li>Emergent behaviors in multi-agent ecosystems</li>
                            <li>Unintended generalization of capabilities</li>
                            <li>Threat models, risk frameworks, and understanding of intended and unintended harms</li>
                        </ul>
                        
                        <h3><span class="theme-icon">&#9878;</span>Ethics</h3>
                        <ul>
                            <li>Moral responsibility and accountability in autonomous decisions</li>
                            <li>Value alignment across dynamic and uncertain contexts</li>
                            <li>Human manipulation, persuasion, or deception by agents</li>
                            <li>The impact of over-delegation on human autonomy and critical thinking</li>
                            <li>Long-term ethical risks beyond bias and fairness</li>
                        </ul>
                        
                        <h3><i class="fa fa-university theme-icon"></i>Policy and Governance</h3>
                        <ul>
                            <li>Legal liability and accountability frameworks for agentic AI</li>
                            <li>Thresholds for safe deployment and escalation control</li>
                            <li>Dual-use concerns and malicious applications (e.g., cyberwarfare, finance)</li>
                            <li>Auditability and explainability of autonomous behavior over time</li>
                            <li>International governance and standards for agentic AI oversight</li>
                        </ul>
                        
                        <h3><i class="fa fa-shield theme-icon"></i>Cybersecurity, Privacy, and Trust</h3>
                        <ul>
                            <li>Resilience and containment of autonomous and adaptive systems</li>
                            <li>Strategic manipulation of information and infrastructure</li>
                            <li>Cybersecurity and privacy risks from multi-agent interactions (e.g., collusion, conflict escalation)</li>
                            <li>Threat modeling and defenses</li>
                            <li>New paradigms for agent containment and monitoring</li>
                            <li>Frameworks and methods for trust and trustworthiness in Agentic AI</li>
                            <li>Accountability and transparency frameworks</li>
                        </ul>
                        
                        <h3><i class="fa fa-cogs theme-icon"></i>Technology and Architectures</h3>
                        <ul>
                            <li>Planning, memory, and goal management in open environments</li>
                            <li>Tool use, API chaining, and real-world actuation</li>
                            <li>Episodic and semantic memory for long-term autonomy</li>
                            <li>Self-modification and dynamic learning strategies</li>
                            <li>Multi-agent coordination, competition, and negotiation</li>
                            <li>Benchmarking and simulation of persistent agent behavior</li>
                            <li>Scalable human-in-the-loop oversight mechanisms</li>
                            <li>Privacy-enhancing technologies, security solutions for end-to-end protection</li>
                            <li>Agentic AI for Social Simulations</li>
                        </ul>
                    </div>
                </div>
            </section>
            <section id='submission'>
                <div class='container'>
                    <h2>Submission Instructions</h2>
                    <div class='description-content'>
                        <p>We welcome three types of contributions:</p>
                        <ul>
                            <li><strong>Regular Technical Papers</strong> (up to 10 pages)</li>
                            <li><strong>Extended Abstracts</strong> (2–4 pages)</li>
                            <li><strong>Position Papers</strong> (up to 10 pages)</li>
                        </ul>
                        
                        <p>All submissions must follow the same submission guidelines and instructions for the main conference (IEEE <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/call-for-full-papers/' target='_blank'>CogMI</a>, with the IEEE two-column conference format). Templates are available from the IEEE website.</p>
                        
                        <p><strong>Submissions must be made through EasyChair.</strong><br>
                        Select the track: "Workshop on Agentic Intelligence: Risks, Ethics, and Trust (AIRET)"</p>
                        
                        <p>Each submission will be reviewed by the workshop's Program Committee. Accepted papers will be included in the CogMI 2025 Workshop Proceedings, published by IEEE, and will be included in IEEE Xplore. At least one author must register and attend to present the work.</p>
                    </div>
                </div>
            </section>
            <section id='dates'>
                <div class='container'>
                    <h2>Important Dates</h2>
                    <div class='description-content'>
                        <ul class='important-dates'>
                            <li><strong>Submission deadline:</strong> Sep 25, 2025</li>
                            <li><strong>Acceptance notification:</strong> Oct 10, 2025</li>
                            <li><strong>Author registration deadline:</strong> Oct 20, 2025</li>
                            <li><strong>Camera-ready submission deadline:</strong> Oct 25, 2025</li>
                        </ul>
                        <p style='margin-top: 15px;'><em>Please complete registration and camera-ready submission as soon as possible.</em></p>
                    </div>
                </div>
            </section>
            <section id='registration'>
                <div class='container'>
                    <h2>Registration & Camera-Ready Submission</h2>
                    <div class='description-content'>
                        <h3><i class="fa fa-ticket theme-icon"></i>Author Registration</h3>
                        <p><strong>At least one author must complete Workshop Author registration for each paper accepted.</strong> If you would like to attend both Workshop and Conference, you can complete Conference Author registration instead. Please see the <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/registration/' target='_blank'>registration page</a> for more information.</p>
                        <p><strong>Deadline:</strong> October 20, 2025</p>
                        
                        <h3><i class="fa fa-file-text theme-icon"></i>Camera-Ready Submission</h3>
                        <p>For camera-ready submission, please follow the instructions at the <a href='https://www.sis.pitt.edu/lersais/conference/cogmi/2025/camera-ready/' target='_blank'>camera-ready submission page</a>. Note that all workshop papers are included as part of the IEEE CogMI proceedings.</p>
                        <p><strong>Deadline:</strong> October 25, 2025</p>
                        
                        <h3><i class="fa fa-hotel theme-icon"></i>Hotel Registration</h3>
                        <p>For hotel reservations, please visit the <a href='https://book.passkey.com/event/51107555/owner/2945954/home' target='_blank'>hotel booking page</a>.</p>
                    </div>
                </div>
            </section>
            <section id='organizers'>
                <div class='container'>
                    <h2>Workshop Organizers</h2>
                    
                    <h3>General Co-Chairs</h3>
                    <div class='organizer-grid'>
                        <a href='http://www.yurulin.com/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/yuru_lin.jpg' alt='Yu-Ru Lin'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Yu-Ru Lin</h4>
                                <p class='affiliation'>▸ University of Pittsburgh<br>▸ Pitt Cyber Institute</p>
                            </div>
                        </a>
                        
                        <a href='https://www.sis.pitt.edu/jjoshi/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/james_joshi.png' alt='James Joshi'>
                            </div>
                            <div class='organizer-info'>
                                <h4>James Joshi</h4>
                                <p class='affiliation'>▸ University of Pittsburgh</p>
                            </div>
                        </a>
                        
                        <a href='https://scholars.cmu.edu/4994-tae-wan-kim' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/tae_wan_kim.png' alt='Tae Wan Kim'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Tae Wan Kim</h4>
                                <p class='affiliation'>▸ Carnegie Mellon University</p>
                            </div>
                        </a>
                    </div>
                    
                    <h3>Program Committee Co-Chairs</h3>
                    <div class='organizer-grid'>
                        <a href='https://www.cs.emory.edu/~kshu5/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/kai_shu.png' alt='Kai Shu'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Kai Shu</h4>
                                <p class='affiliation'>▸ Emory University</p>
                            </div>
                        </a>
                        
                        <a href='https://emiehling.github.io/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/erik_miehling.png' alt='Erik Miehling'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Erik Miehling</h4>
                                <p class='affiliation'>▸ IBM Research</p>
                            </div>
                        </a>
                    </div>
                    
                    <h3>Publicity Chair</h3>
                    <div class='organizer-grid'>
                        <a href='https://andaqu.github.io/' target='blank' class='organizer-card'>
                            <div class='organizer-image'>
                                <img src='images/andrew_aquilina.jpg' alt='Andrew Aquilina'>
                            </div>
                            <div class='organizer-info'>
                                <h4>Andrew Aquilina</h4>
                                <p class='affiliation'>▸ University of Pittsburgh</p>
                            </div>
                        </a>


                        <div class='organizer-card' style='opacity:0; pointer-events:none; height:0; overflow:hidden;'></div>

                    </div>
                   
                </div>
            </section>
            <section id='sponsors'>
                <div class='container'>
                    <h2>Sponsors</h2>
                    <div class='sponsors-content'>
                        <p>We gratefully acknowledge the support of our sponsors:</p>
                        <div class='sponsors-images'>
                            <img src='images/rds.png' alt='University of Pittsburgh - Office of the Provost Responsible Data Science'>
                            <img src='images/cyber.png' alt='University of Pittsburgh - Institute for Cyber Law, Policy, and Security'>
                        </div>
                    </div>
                </div>
            </section>
        </div>
    </div>
</body>
</html> 
